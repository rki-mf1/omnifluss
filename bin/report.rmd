---
title: "Flupipe Report"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 6
    mathjax: null
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
  proj_folder: "none"
  list_folder: "none"
  min_cov: "none"
  reference: false
  rki_sample_name: true
  run_name: "none"
  version: "none"
---

<style>
  .superwideimage{
      overflow-x:scroll;
      white-space: nowrap;
  }

  .superwideimage img{
     max-width: none;
  }

</style>

<style>
  .superhighimage{
      overflow:auto;
      height: 500px;
      width: 100%;
      margin-top: 10px;
      margin-bottom:
  }

</style>

<style type="text/css">
.main-container {
  max-width: 100% !important;
  margin: auto;
}
</style>

```{r setup, include=FALSE}
# .libPaths("/home/ternovojd/scratch/VirusGE/R")
#.libPaths("/home/ternovojd/scratch/VirusGE/R_430")
# turn off warnings
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, error = FALSE, time_it = TRUE)
# load libraries
library("data.table")
library("formattable")
library("ggplot2")
library("kableExtra")
library("plyr")
library("rjson")
library("reshape2")
library("ShortRead")
library("dplyr")

stepsize=20
n_content_threshold=5

#create folder for files generated during report creation
if (!dir.exists(params$list_folder)) {
  dir.create(params$list_folder)
}

```
```{r def_functions}
# input of file listing. requires file names like /path/to/nCoV1.bamstats.txt
f.get_filenames <- function(l.input){
    sapply(l.input, function(x){
        filename <- unlist(strsplit(x, '/'))[length(unlist(strsplit(x, '/')))]
        samplename <- unlist(strsplit(filename, '\\.'))[1]
        return(samplename)
    })
    #returns named character vector of sample names, e.g. nCoV1
}

# modified color_bar to fix direction from "rtl" to "ltr"
f.color_bar <- function (color = "lightgray", fun = "proportion",
    ...)
{
    fun <- match.fun(fun)
    formattable::formatter("span", style = function(x) style(display = "inline-block",
        direction = "ltr", `border-radius` = "4px",
        `padding-right` = "2px", `background-color` = csscolor(color),
        width = percent(fun(as.numeric(x), ...))))
}

  # Function to collapse the values within a grouped dataframe
collapse_rows_df <- function(df, variable){
    group_var <- enquo(variable)
    df %>%
      group_by(!! group_var) %>%
      mutate(groupRow = 1:n()) %>%
      ungroup() %>%
      mutate(!!quo_name(group_var) := ifelse(groupRow == 1, 
      as.character(!! group_var), "")) %>%
      select(-c(groupRow))
  }

# for final plot
baseContent <- function(x) {
  alf <- as.data.frame(alphabetFrequency(x, as.prob=TRUE)*100)
  return(alf)
}
baseContentCount <- function(x) {
  alf <- as.data.frame(alphabetFrequency(x, as.prob=FALSE))
  return(alf)
}
infer_segment_name <- function(x) {
  split = unlist(strsplit(x,"\\|"))
  return(split[length(split)])
}
#temporary solution
infer_sample_name <- function(x) {
  return(paste(unlist(strsplit(x,"_"))[seq(1,5)],collapse="_"))
}
```
```{r get_cmd_line_parameters}
  # kraken_folder = "/home/ternovojd/scratch/VirusGE/igsmp/reporting/data/kraken"
  # mapping_stats_folder = "/home/ternovojd/scratch/VirusGE/igsmp/reporting/data/mapping_stats" #run219 - start here and pull the data from here
  # fasta.dir = "/home/ternovojd/scratch/VirusGE/igsmp/reporting/data/consensuses_iupac"

  min.coverage <- as.numeric(params$min_cov)

  #commented out for now
  # l.dirlist <- list.dirs(file.path(params$proj_folder), recursive = F)
  # kraken_folder <- file.path(params$proj_folder,"kraken","classification")

  # mapping_stats_folder <- l.dirlist[grepl(pattern = "mapping_stats", x = l.dirlist)]
  # fasta.dir <- file.path(params$proj_folder,"data","consensuses_iupac")
  # mapping_folder <- l.dirlist[grepl(pattern = "mapping", x = l.dirlist)]
  # trimmed_folder <- l.dirlist[grepl(pattern = "trimmed", x = l.dirlist)]

  #kraken
  kraken_run <- FALSE
  kraken_folder <- file.path(params$proj_folder,"kraken","classification")
  if (!dir.exists(kraken_folder) || length(kraken_folder) == 0) {
      kraken_run <- FALSE
  } else {
      kraken_run <- TRUE
  }

```
```{r read_data}
# for read counts
l.infiles.trimming <- list.files(path=".",
                                 pattern = "*.fastp.json$",
                                 full.names = T,
                                 recursive = F)

names(l.infiles.trimming) <- f.get_filenames(l.infiles.trimming)

# for kraken
l.infiles.kraken <- list()
l.infiles.kraken <- list.files(path=".",
                                pattern = "*.report.txt$",
                                full.names = T,
                                recursive = F)

names(l.infiles.kraken) <- f.get_filenames(l.infiles.kraken)

# for mapping statistics
# l.infiles.bamstats handled further down


l.infiles.read.duplicates <- list.files(path=".",
                                 pattern = "*.MarkDuplicates.metrics.txt$",
                                 full.names = T,
                                 recursive = F)

names(l.infiles.read.duplicates) <- f.get_filenames(l.infiles.read.duplicates)

# for coverage plot
l.infiles.coverage <- list.files(path=".",
                                pattern = "*.coverage.tsv$",
                                full.names = T,
                                recursive = T)

names(l.infiles.coverage) <- f.get_filenames(l.infiles.coverage)

l.infiles.bamstats.coverage <- list.files(path=".",
                                 pattern = "*.samtools_coverage.txt$",
                                 full.names = T,
                                 recursive = T)

names(l.infiles.bamstats.coverage) <- f.get_filenames(l.infiles.bamstats.coverage)

#TODO - can't take consensus sequences from the WF, because the "renaming" of the reference isn't implemented yet
l.infiles.fasta.files <- list.files(path = file.path(params$proj_folder,"bcftools","consensus"),
                                 pattern = "_tmp.fa$",
                                 full.names = T,
                                 recursive = F)

names(l.infiles.fasta.files) <- f.get_filenames(l.infiles.fasta.files)

# for consensus sequence table 
#TODO - for later when automatic reference selection is implemented
# l.infiles.read.ranking.refs <- list.files(path = file.path(params$proj_folder,"placeholder")
#                                  pattern = glob2rx("Ranking_top5_Refs_*.txt$"),
#                                  full.names = T,
#                                  recursive = T)

#this has to be removed (not necessary for the new implementation)
# names(l.infiles.read.ranking.refs) <- f.get_filenames(l.infiles.read.ranking.refs)

```

### Read counts

Raw reads were subjected to adapter clipping.
The following table summarizes the read count per sample before and after trimming. Additionally, the percentage of remaining reads after trimming is listed.

```{r read_trimming}

l.trimming.data.json <- lapply(l.infiles.trimming, function(x){
    fromJSON(file = x)
})

df.trimming.data <- ldply(l.trimming.data.json, function(e){
    df.before <- as.data.frame(do.call(rbind, e$summary$before_filtering))
    colnames(df.before) <- c("before.trimming")
    df.after  <- as.data.frame(do.call(rbind, e$summary$after_filtering))
    colnames(df.after) <- c("after.trimming")

    df.output <- data.frame(feature = rownames(df.before),
                            before = df.before$before.trimming,
                            after = df.after$after.trimming)
    return(df.output)
})

# rename 1st column
tmp <- colnames(df.trimming.data)
tmp[1] <- c("sample")
colnames(df.trimming.data) <- tmp

df.filter.data <- ldply(l.trimming.data.json, function(e){

    df.output <- data.frame(passed_filter = e$filtering_result$passed_filter_reads,
                            low_qual = e$filtering_result$low_quality_reads,
                            high_N = e$filtering_result$too_many_N_reads,
                            low_complex = e$filtering_result$low_complexity_reads,
                            short = e$filtering_result$too_short_reads
                            )
    return(df.output)
})

# rename 1st column
tmp <- colnames(df.filter.data)
tmp[1] <- c("sample")
colnames(df.filter.data) <- tmp
```

```{r table_trimming}
df.summary <- data.frame(sample = unique(df.trimming.data$sample),
                        reads.before.clip = df.trimming.data$before[grepl("total_reads", df.trimming.data$feature)],
                        reads.after.clip  = df.trimming.data$after[grepl("total_reads", df.trimming.data$feature)],
                        percentage.after.clip = df.trimming.data$after[grepl("total_reads", df.trimming.data$feature)]*100/df.trimming.data$before[grepl("total_reads", df.trimming.data$feature)]
)
df.table <- df.summary
# add coloured bar charts to table
df.table$reads.before.clip <- f.color_bar("lightgreen")(df.table$reads.before.clip)
df.table$reads.after.clip <- f.color_bar("lightgreen")(df.table$reads.after.clip)
df.table$percentage.after.clip <- Map(paste,format(round(df.table$percentage.after.clip,2),nsmall=2),"%")

kbl(x = df.table,
    col.names = c("sample", "reads before trim", "reads after trim", "% of reads after trimming"),
    digits = 2,
    escape = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T, full_width = T) %>%
  scroll_box(height = "400px")

# save table as csv for later use
write.csv(  x=df.summary,
            row.names = FALSE,
            file = file.path(params$list_folder, "read_stats.csv")
          )
```

```{r read_coverage_preanalyses}
# read file content
# dt.coverage is used again later for plotting
dt.coverage <- as.data.table(ldply(l.infiles.coverage, fread, sep='\t'))
colnames(dt.coverage) <- c("sample","chromosome", "position", "depth")

# rename chromosome column values
dt.coverage$chromosome <- sapply(dt.coverage$chromosome, function(x){
  segment <- tail(unlist(strsplit(x,"|",fixed=TRUE)), n=1)
  segment <- toString(segment)
  return(segment)
})

dt.output <- dt.coverage[, sum(depth > 10), by = sample]
setnames(dt.output, "V1", "covered.bases")
dt.output$genome.length <- dt.coverage[,length(depth), by = sample]$V1
dt.output$genome.coverage <- dt.output$covered.bases / dt.output$genome.length

### taking directly the per chromosome results from bamstats coverage
### this data frame is used again later for the whole table including all samples

dt.bamstats.coverage <- as.data.table(ldply(l.infiles.bamstats.coverage, fread, sep='\t', select=c(1,4,6,7)))
dt.bamstats.coverage[,("coverage") := round(.SD,2), .SDcols="coverage"]
dt.bamstats.coverage[,("meandepth") := round(.SD,0), .SDcols="meandepth"]
colnames(dt.bamstats.coverage) <- c("sample","chromosome","reads mapped [%]", "coverage [%]", "mean depth [bp]")

# rename chromosome column values
dt.bamstats.coverage$chromosome <- sapply(dt.bamstats.coverage$chromosome, function(x){
  segment <- tail(unlist(strsplit(x,"|",fixed=TRUE)), n=1)
  segment <- toString(segment)
  return(segment)
})

dt.bamstats.coverage <- reshape(dt.bamstats.coverage, idvar = "sample", timevar = "chromosome", direction = "wide")

# adding placeholder column(s) for missing segment(s)
ls.segment <- list("*HA","*NA","*MP","*NP","*NS","*PA","*PB1","*PB2")
substrRight <- function(x, n){substr(x, nchar(x)-n+1, nchar(x))}

if (ncol(dt.bamstats.coverage) != 25 ) {
    for (s in ls.segment){
      if (Reduce("|",grepl(s, names(dt.bamstats.coverage)))) {}
      else {
        dt.bamstats.coverage[,paste("reads mapped [%].", substrRight(s, 2))] <- NA
        dt.bamstats.coverage[,paste("coverage [%].", substrRight(s, 2))] <- NA
        dt.bamstats.coverage[,paste("mean depth [bp].", substrRight(s, 2))] <- NA
        }
  }
}

# reorder dataframe columns
dt.bamstats.coverage <- dt.bamstats.coverage[, c( "sample","reads mapped [%].HA","coverage [%].HA","mean depth [bp].HA",
                                                  "reads mapped [%].NA","coverage [%].NA","mean depth [bp].NA",
                                                  "reads mapped [%].MP","coverage [%].MP","mean depth [bp].MP",
                                                  "reads mapped [%].NP","coverage [%].NP","mean depth [bp].NP",
                                                  "reads mapped [%].NS","coverage [%].NS","mean depth [bp].NS",
                                                  "reads mapped [%].PA","coverage [%].PA","mean depth [bp].PA",
                                                  "reads mapped [%].PB1","coverage [%].PB1","mean depth [bp].PB1",
                                                  "reads mapped [%].PB2","coverage [%].PB2","mean depth [bp].PB2" )]

###################### Joining the 2 datasets ##################################
colnames(dt.output) <- c("sample", "ref.coverage [bp]", "genome.length", "ref.coverage [fraction]")
dt.output <- merge(dt.output, dt.bamstats.coverage, by = "sample")
```

```{r read_coverage}
# read file content
# dt.coverage <- as.data.table(ldply(l.infiles.coverage, fread, sep='\t'))
# colnames(dt.coverage) <- c("sample","chromosome", "position", "depth")

# reduce amount of data points to be plotted
dt.coverage[, bin:=rep(seq(1, ceiling(length(position) / 100)), each = 100, length.out = length(position)), by = "sample"]
dt.coverage[, mid.bin:=seq(1,length(position)) %% 100 ]
dt.coverage[, mean.cov:=mean(depth), by=c("sample", "bin")]

# adding placeholder row(s) for missing segment(s)
ls.segment <- list("*HA","*NA","*MP","*NP","*NS","*PA","*PB1","*PB2")

for (s in unique(dt.coverage$sample)){
  tmp <- dt.coverage[dt.coverage$sample == as.character(s),]
  for (l in ls.segment){
    if (Reduce("|",grepl(l, unique(tmp$chromosome)))) {}
    else {
      new_row <- list(s, substrRight(l,2), 0, NA, NA, 50, 1)
      dt.coverage <- rbind(dt.coverage, new_row)
    }
  }
  rm(tmp)
}

dt.coverage <- dt.coverage %>% group_by(chromosome)
dt.coverage <- dt.coverage %>% arrange(factor(chromosome, levels = c("HA","NA","MP","NP","NS","PA","PB1","PB2")))
dt.coverage <- dt.coverage %>% group_by(sample)
dt.coverage$chromosome = factor(dt.coverage$chromosome, levels=c("HA","NA","MP","NP","NS","PA","PB1","PB2"))
```
```{r read_kraken}
    # Kraken2 output column labels.
    # Percentage of fragments covered by the clade rooted at this taxon
    # Number of fragments covered by the clade rooted at this taxon
    # Number of fragments assigned directly to this taxon
    # A rank code, indicating (U)nclassified, (R)oot, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. Taxa that are not at any of these 10 ranks have a rank code that is formed by using the rank code of the closest ancestor rank with a number indicating the distance from that rank. E.g., "G2" is a rank code indicating a taxon is between genus and species and the grandparent taxon is at the genus rank.
    # NCBI taxonomic ID number
    # Indented scientific name

  df.kraken_output <- data.frame()
  if (kraken_run) {
      dt.kraken_data <- ldply(l.infiles.kraken, fread)
      colnames(dt.kraken_data) <- c("Sample", "read_ratio", "read_count", "read_count_specific", "rank", "ncbi_taxid", "sciname")
      # select unclassified and tax id's for Orthomyxoviridae (11308), Influenza A (11320) and B (11520), and Human (9606)
      df.kraken_output <- dt.kraken_data[dt.kraken_data$ncbi_taxid %in% c(0,"11308","11320","11520","9606"), c("Sample", "read_ratio", "read_count", "ncbi_taxid", "sciname")]

      # make tables wide for absolute and relative read counts
      dt.kraken.count <- data.table::dcast(as.data.table(df.kraken_output), Sample ~ sciname, value.var = c("read_count"))
      dt.kraken.count[is.na(dt.kraken.count)] <- 0
      df.kraken_output <- data.table::dcast(as.data.table(df.kraken_output), Sample ~ sciname, value.var = c("read_ratio"))
      df.kraken_output[is.na(df.kraken_output)] <- 0
      
      # Add placeholder for missing columns 
      species <- c("Sample","Homo sapiens", "Influenza A virus", "Influenza B virus", "Orthomyxoviridae", "unclassified")
      #df.kraken_output
      for (sp in species) {
        if (Reduce("|",grepl(sp, colnames(df.kraken_output)))) {
          # do nothing if column exist
        }
        else {
          df.kraken_output <- cbind(df.kraken_output, new_col = 0)
          colnames(df.kraken_output)[which(names(df.kraken_output) == "new_col")] <- sp
          }
      }
      #dt.kraken.count
      for (sp in species) {
        if (Reduce("|",grepl(sp, colnames(dt.kraken.count)))) {
          # do nothing if column exist
        }
        else {
          dt.kraken.count <- cbind(dt.kraken.count, new_col = 0)
          colnames(dt.kraken.count)[which(names(dt.kraken.count) == "new_col")] <- sp
          }
      }  
      colnames(df.kraken_output) <- paste0(colnames(df.kraken_output), c("", " [%]", " [%]", " [%]", " [%]", " [%]" ))
      
      df.kraken_output$`filter passed` <- rowSums(dt.kraken.count[,c("Homo sapiens", "Influenza A virus", "Influenza B virus")]) *2
      #print(colnames(df.kraken_output))
      df.kraken_output <- df.kraken_output[, c("Sample", "filter passed", "Homo sapiens [%]", "Influenza A virus [%]", "Influenza B virus [%]", "Orthomyxoviridae [%]", "unclassified [%]")]
  }
```


### Taxonomic Read Classification

The taxonomic classification of reads can not only serve to identify contamination, but also enable the filtering of reads assigned to certain taxa. In this step influena A, influenza B and Orthomyxoviridae reads were filtered and used for the next analysis step. Remaining reads were excluded from further analysis.

The assigned taxa are listed by sample n the following table.

```{r table_kraken, fix.cap="Read counts after species binning using Kraken."}
if (kraken_run) {
    #params_list_folder="/home/ternovojd/scratch/VirusGE/igsmp/reporting/output"
      # save table as csv for later use
    write.csv(  x=df.kraken_output,
                row.names = FALSE,
                file = file.path(params$list_folder, "species_filtering.csv")
    )

    kbl(df.kraken_output) %>%
        kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>%
        scroll_box(height = "400px")
}
```

```{r reshape_kraken_barchart}
if (kraken_run) {
    # reshape dataframe for  plotting
        # add column for diff of ortho and infA + infB (for barplot)
    df.kraken_output$diff_orthomyxoviridae  <- df.kraken_output$`Orthomyxoviridae [%]`-(df.kraken_output$`Influenza A virus [%]` + df.kraken_output$`Influenza B virus [%]`)
    
    df.kraken_output.reshaped <- reshape(df.kraken_output,
                     varying=names(df.kraken_output)[3:8],
                     direction="long", idvar=c("Sample"),
                     v.names="ratio", timevar="tax")
    df.kraken_output.reshaped$tax <- factor(df.kraken_output.reshaped$tax,
                                      levels = c(1, 2, 3, 4, 5, 6),
                                      labels = names(df.kraken_output)[3:8])
    df.kraken_output.reshaped$Sample <- factor(df.kraken_output.reshaped$Sample)
    df.kraken_output.reshaped$tax <- factor(df.kraken_output.reshaped$tax)
}
```
<div class=superhighimage>
```{r kraken_plot_barchart, fig.align='center', fig.cap="Taxonimical Classification of the Samples."}
if (kraken_run) {
  df.kraken.barplot <- df.kraken_output.reshaped[df.kraken_output.reshaped$tax %in% c("Homo sapiens [%]", "Influenza A virus [%]", "Influenza B virus [%]", "unclassified [%]", "diff_orthomyxoviridae"), ]
  
  samples <- unique(df.kraken.barplot$Sample)
  if (length(samples)>stepsize) {
    for (s in 0:(ceiling(length(samples)/stepsize)-1)){
      x = s*stepsize
      y = ((s+1)*stepsize)-1
      if (y>length(samples)){y = length(samples)}
      df.subset <- subset(df.kraken.barplot, Sample %in% samples[x:y])
      
      g <- ggplot(data=df.subset, aes(fill=tax, y=Sample, x=ratio)) +
          geom_bar(position="stack", stat="identity", width = 0.6) +
          labs(title = "Taxanomic Classification", fill = "") +
          theme(legend.position = 'top', legend.text = element_text(size = 7),
                legend.title = element_text(size=8)) +
          guides(fill = guide_legend(label.position = "bottom",
                                     title.position = "left", title.vjust = 1)) +
          scale_fill_brewer(palette="Set1", labels = c("Homo Sapiens", "Influenza A", "Influenza B", "unclassified", "Orthomyxoviridae"))
    }
  } else {
    ggplot(data=df.kraken.barplot, aes(fill=tax, y=Sample, x=ratio)) +
          geom_bar(position="stack", stat="identity", width = 0.6) +
          labs(title = "Taxanomic Classification", fill = "") +
          theme(legend.position = 'top', legend.text = element_text(size = 7),
                legend.title = element_text(size=8)) +
          guides(fill = guide_legend(label.position = "bottom",
                                     title.position = "left", title.vjust = 1)) +
          scale_fill_brewer(palette="Set1", labels = c("Homo Sapiens", "Influenza A", "Influenza B", "unclassified", "Orthomyxoviridae"))
  }
}
```
</div>
```{r kraken_cleanup}
if (kraken_run) {
  rm(dt.kraken.count)
  rm(df.kraken_output)
  rm(dt.kraken_data)
  rm(df.kraken_output.reshaped)
  rm(df.kraken.barplot)
}
```

## Mapping statisics

Reads were mapped to the reference genome using BWA. For each sample the number of mapped read as well as the overall mapping rate and the rate of duplicated reads are listed in the following table. Additionally, the genome coverage, the mean read depth and the rate of mapped reads are listed for each genome fragment.

```{r read_mappingstats}
# if the bamstats were preprocessed before, don't do it again
# else preprocess bamstats and read in processed ones

l.infiles.bamstats <- list.files(
                                 pattern = "*.sorted.bam.piped.flagstat$",
                                 full.names = T,
                                 recursive = F)

if (length(l.infiles.bamstats) != 0) {

  names(l.infiles.bamstats) <- f.get_filenames(l.infiles.bamstats)

} else {

  l.infiles.bamstats <- list.files(
                                  pattern = "*.sorted.bam.flagstat$",
                                  full.names = T,
                                  recursive = F)

  names(l.infiles.bamstats) <- f.get_filenames(l.infiles.bamstats)

  ### newly added
  for (name in names(l.infiles.bamstats)){

      lines <- readLines(l.infiles.bamstats[[name]])
      lines <- sub(" \\+ ","|", lines)
      lines <- sub(" ", "|", lines)

      write(lines, sub("\\.flagstat$",".piped.flagstat",l.infiles.bamstats[[name]]))

  }

  l.infiles.bamstats <- list.files(
                                  pattern = "*.piped.flagstat$",
                                  full.names = T,
                                  recursive = T)

  names(l.infiles.bamstats) <- f.get_filenames(l.infiles.bamstats)
}


###
df.bamstat.data <- ldply(l.infiles.bamstats, fread, sep = '|')
colnames(df.bamstat.data) <- c("sample", "count", "unknown", "description")
```

```{r read_duplicates}
# read file content
dt.read.duplicates <- as.data.table(ldply(l.infiles.read.duplicates, fread, sep='\t', select = c(9), skip=6, nrow=1)) 
colnames(dt.read.duplicates) <- c("sample","reads duplicated [%]")
dt.read.duplicates$`reads duplicated [%]` <- round(dt.read.duplicates$`reads duplicated [%]` * 100, digits = 2)
```

```{r table_bamstats}
df.output <- data.frame("sample" = unique(df.bamstat.data$sample),
                        "input" = df.bamstat.data$count[grepl("in total", df.bamstat.data$description)],
                        "mapped" = df.bamstat.data$count[grepl("properly paired", df.bamstat.data$description)])

df.output$mapping.rate <- round((df.output$mapped / df.output$input)*100, digits = 2)
colnames(df.output) <- c("sample", "reads in", "reads mapped", "mapping rate [%]")

# save table as csv for later use
write.csv(  x=df.output,
            row.names = FALSE,
            file = file.path(params$list_folder, "mapping_stats.csv")
)

# merge read per segment, duplication data with bamstats table
df.mapping.table <- merge(df.output, dt.read.duplicates, by="sample")
##### bamstats coverage table from above is reused 
df.mapping.table <- merge(df.mapping.table, dt.bamstats.coverage, by="sample")

# replace dots in column names with space
sub.dots <- function(df) {names(df) <- sub("\\.", " ", names(df));df}
df.mapping.table <- sub.dots(df.mapping.table)

# convert reads mapped per segment column values to mapping rate
seg_col_range <- seq(6,29, by=3) # taking every third segment column
df.mapping.table[, c(seg_col_range)] <- lapply(df.mapping.table[, c(seg_col_range)], function(x) round((x / as.numeric(df.mapping.table$`reads mapped`)*100), digits = 2))

df.mapping.table$`reads in` <- f.color_bar("lightgreen")(df.mapping.table$`reads in`)
df.mapping.table$`reads mapped` <- f.color_bar("lightgreen")(df.mapping.table$`reads mapped`)

write.csv(  x=df.mapping.table,
            row.names = FALSE,
            file = file.path(params$list_folder, "mapping_statistics.csv")
)

kbl(df.mapping.table,
    digits = 3,
    escape = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>%
  scroll_box(height = "400px")
```

```{r bamstats_cleanup}
rm(df.bamstat.data)
rm(dt.bamstats.coverage)
rm(df.output)
rm(df.mapping.table)
```

### Coverage Distribution

The following plots show the read coverage of each sample after mapping. In 100 bp steps the mean read depth was calculated and plotted. Please be aware of the varying x and y axis scaling of the samples. The dotted read line shows the minimal required read depth.

#### Sequence depth distribution on reference genome

Sequence depth was calculated at each position and plotted. The aim for positive samples is an evenly distributed high sequence depth.
The plot shows the sequence depth distribution on each segment. The positions were divided into bins with size of 100. In each bin the mean of the depths were then calculated and plotted. Please be aware of the varying x axis scaling.

<div class=superhighimage>

```{r plot_coverage, fig.width=10, fig.height=3}

# https://stackoverflow.com/questions/39119917/how-to-add-a-legend-to-hline
sample.names <- unique(dt.coverage$sample)
 for (s in c(sample.names)){
   plt <- ggplot(dt.coverage[(dt.coverage$sample == s) & (dt.coverage$mid.bin == 50),],
         aes(x=position, y=mean.cov, fill = chromosome, colour = chromosome)) +
         labs(title = paste("coverage distribution of", s, sep = " "), y = "mean coverage",
               fill = "chromosome") +
         geom_bar(stat = "identity", width = 1) +
         facet_grid(~chromosome, switch = 'y', scales = "free_x") +
         scale_x_continuous(limits = c(0,NA)) +
         theme(axis.text.x = element_text(angle = 45, size = 10, hjust = 1)) +
         geom_hline(aes(yintercept=min.coverage,
               linetype = paste("minimal coverage = ",as.character(min.coverage))),
               colour = "red", linewidth = 0.5) +
         scale_linetype_manual(name = "threshold", values = c(2),
               guide = guide_legend(override.aes = list(color = c("red")))) +
         theme(legend.key.size = unit(0.5, 'cm'), legend.title = element_text(size = 10),
               legend.text = element_text(size=8))
    print(plt)
 }
```

```{r coverage_cleanup}
rm(dt.coverage)
```

</div>












The following table lists the N content, as well as the rate of ambiguous bases (none ATGCN characters) in the consensus sequence per sample and segment. % N's that are larger than the given threshold of 5% is marked in red. 

```{r read_fasta_files}
dt.fasta <- readDNAStringSet(l.infiles.fasta.files)
sample.names = unlist(lapply(names(dt.fasta), infer_sample_name))
segment.names <- unlist(lapply(names(dt.fasta), infer_segment_name))

# Base Content Probability
l.res <- baseContent(dt.fasta)
l.res["Sample"] <- sample.names
l.res["Segment"] <- segment.names
#l.res["nonBase"] <- 100-rowSums(l.res[c("G","C","A","T","N")])
l.res["nonBase"] <- rowSums(l.res[c("M","R","W","S","Y","K","V","H","D","B","-","+",".")]) #this avoids rounding errors
l.res <- select(l.res, c("Sample", "Segment", "N", "nonBase"))
l.res <- reshape(l.res, v.names=c("N", "nonBase"), timevar="Segment", idvar="Sample",
        direction="wide")
#row.names(l.res) <- NULL

# Base Content Count
l.res.count <- baseContentCount(dt.fasta)
l.res.count["nonBase"] <- rowSums(l.res.count) - rowSums(l.res.count[c("G","C","A","T","N")])
l.res.count["Sample"] <- sample.names
l.res.count["Segment"] <- segment.names
l.res.count <- select(l.res.count, c("Sample", "Segment", "N", "nonBase"))
l.res.count <- reshape(l.res.count, v.names=c("N", "nonBase"), timevar="Segment", idvar="Sample",
        direction="wide")
```

```{r reshape_Base_content_table}
# initialize tmp dataframes as placeholder and for reshaping purposes
n <- length(l.infiles.fasta.files)
base.Ncontent.table <- data.frame("Sample" = l.res$Sample,
                                 "base_freq" = rep("% N's", n),
                                 "HA" = numeric(n),"NA" = numeric(n), 
                                 "MP" = numeric(n),"NP" = numeric(n),
                                 "NS" = numeric(n), "PA" = numeric(n),
                                 "PB1" = numeric(n), "PB2" = numeric(n)
                                 )
colnames(base.Ncontent.table)[colnames(base.Ncontent.table) %in% c("NA.")] <- c("NA")


base.Ncontent.count.table <- data.frame("Sample" = l.res.count$Sample,
                                 "base_freq" = rep("N count", n),
                                 "HA" = numeric(n),"NA" = numeric(n), 
                                 "MP" = numeric(n),"NP" = numeric(n),
                                 "NS" = numeric(n), "PA" = numeric(n),
                                 "PB1" = numeric(n), "PB2" = numeric(n)
                                 )
colnames(base.Ncontent.count.table)[colnames(base.Ncontent.count.table) %in% c("NA.")] <- c("NA")

base.NonBasecontent.table <- data.frame("Sample" = l.res$Sample,
                                 "base_freq" =  rep("% non ATGCN's", n),
                                 "HA" = numeric(n), "NA" = numeric(n), 
                                 "MP" = numeric(n), "NP" = numeric(n),
                                 "NS" = numeric(n), "PA" = numeric(n),
                                 "PB1" = numeric(n), "PB2" = numeric(n)
                                 )
colnames(base.NonBasecontent.table)[colnames(base.NonBasecontent.table) %in% c("NA.")] <- c("NA")

base.NonBasecontent.count.table <- data.frame("Sample" = l.res.count$Sample,
                                 "base_freq" =  rep("non ATGCN count", n),
                                 "HA" = numeric(n), "NA" = numeric(n), 
                                 "MP" = numeric(n), "NP" = numeric(n),
                                 "NS" = numeric(n), "PA" = numeric(n),
                                 "PB1" = numeric(n), "PB2" = numeric(n)
                                 )
colnames(base.NonBasecontent.count.table)[colnames(base.NonBasecontent.count.table) %in% c("NA.")] <- c("NA")

# assign corresponding values to each segment; fill the previously generated tables
segments <- list("HA","NA","MP","NP","NS","PA","PB1","PB2")
for (s in segments) {
  colN <- paste("N.", s, sep = "")
  colnonBase <- paste("nonBase.", s, sep = "")
  if( all(c(colN, colnonBase) %in% colnames(l.res))) {
    base.Ncontent.table[s] <- lapply(lapply(l.res[colN], round , 3), as.character)
    base.Ncontent.count.table[s] <- lapply(lapply(l.res.count[colN],round,0), as.character)
    base.NonBasecontent.table[s] <- lapply(lapply(l.res[colnonBase], round, 3), as.character)
    base.NonBasecontent.count.table[s] <- lapply(lapply(l.res.count[colnonBase], round,0), as.character)
  }
}

# join tables for clean csv
tmp_base.N.table <- rbind(base.Ncontent.table, base.Ncontent.count.table)
tmp_base.non.base.table <- rbind(base.NonBasecontent.table, base.NonBasecontent.count.table)
tmp_base.content.table <- rbind(tmp_base.N.table, tmp_base.non.base.table)
tmp_base.content.table <- tmp_base.content.table[order(tmp_base.content.table$Sample),]
tmp_base.content.table$index <- 1:nrow(tmp_base.content.table)
#row.names(tmp_base.content.table) <- NULL
write.csv(x = tmp_base.content.table[,1:10],
          row.names = FALSE,
          file = file.path(params$list_folder, "N_content_and_Ambigiuos_calls.csv")
)

############# marking samples with over 5% N content ###########################
for (s in segments) {
  c = ifelse(as.numeric(unlist(base.Ncontent.table[s])) < n_content_threshold | is.na(base.Ncontent.table[s]), "black", "red")
  base.Ncontent.table[s] <- cell_spec(as.numeric(unlist(base.Ncontent.table[s])), color = c)
}
# join tables
base.N.table <- rbind(base.Ncontent.table, base.Ncontent.count.table)
base.non.base.table <- rbind(base.NonBasecontent.table, base.NonBasecontent.count.table)
base.content.table <- rbind(base.N.table, base.non.base.table)
base.content.table <- base.content.table[order(base.content.table$Sample),]
base.content.table$index <- 1:nrow(base.content.table)
```

```{r table_base_content}
# https://stackoverflow.com/questions/2288485/how-to-convert-a-data-frame-column-to-numeric-type
# Format table
base.content.table[,1:10] %>% 
  group_by(Sample) %>% 
  slice(1:4) %>% 
  select(Sample, everything()) %>% 
  collapse_rows_df(Sample) %>%
  formattable() %>%
  kbl(col.names = NULL, align = c("l"), escape = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T,
                full_width = F) %>%
  add_header_above(c("Sample"=2,"HA"=1,"NA"=1,"MP"=1,"NP"=1,
                      "NS"=1,"PA"=1,"PB1"=1,"PB2"=1)) %>%
  row_spec(seq(1,nrow(base.content.table),4), background="#EEEEEE") %>% 
  column_spec(1, color = "black" , background = "#EEEEEE")  #%>%
  #scroll_box(height = "400px")
```

```{r base_content_cleanup}
rm(base.Ncontent.table)
rm(base.NonBasecontent.table)
rm(base.content.table)
```